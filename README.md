# ğŸ¤– Snowflake NLP Agent v2

Una aplicaciÃ³n web inteligente construida con Streamlit que permite realizar consultas en lenguaje natural (espaÃ±ol) a bases de datos Snowflake, utilizando LangChain con soporte dual para Groq/Llama y Google Gemini para conversiÃ³n automÃ¡tica de texto a SQL con detecciÃ³n hÃ­brida de consultas.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/streamlit-1.28+-red.svg)
![Snowflake](https://img.shields.io/badge/snowflake-supported-blue.svg)

## ğŸŒŸ CaracterÃ­sticas Principales

- **ğŸ’¬ Interfaz de Chat Intuitiva**: ConversaciÃ³n natural con tu base de datos
- **ğŸ§  Procesamiento NLP HÃ­brido**: DetecciÃ³n inteligente de consultas (BD vs ayuda vs fuera de contexto)
- **ğŸ”„ Soporte Dual de LLM**: Compatible con Groq/Llama y Google Gemini con auto-detecciÃ³n
- **ğŸ“Š VisualizaciÃ³n Inteligente**: Formateo automÃ¡tico de resultados con tablas interactivas
- **ğŸ”’ ConexiÃ³n Segura**: IntegraciÃ³n robusta con Snowflake usando credenciales encriptadas
- **ğŸ¯ Respuestas Educativas**: GuÃ­a inteligente para usuarios con ejemplos y redirecciÃ³n amigable
- **ğŸ¨ Interfaz Moderna**: DiseÃ±o responsivo con Streamlit y componentes interactivos

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

- Python 3.8+
- Cuenta de Snowflake con credenciales de acceso
- **API Key de Groq** (opciÃ³n 1) para modelos Llama
- **API Key de Google Gemini** (opciÃ³n 2) para modelos Gemini
- Al menos uno de los dos proveedores LLM configurado

### 1. InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/snowflake_nlp_agent_v2.git
cd snowflake_nlp_agent_v2

# Crear y activar entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Instalar dependencias
pip install -r requirements.txt
```

### 2. ConfiguraciÃ³n

```bash
# Copiar template de configuraciÃ³n
cp .env.example .env

# Editar .env con tus credenciales
nano .env
```

Configurar las siguientes variables en `.env`:

```env
# Credenciales Snowflake
SNOWFLAKE_ACCOUNT=tu-account-url
SNOWFLAKE_USER=tu-usuario
SNOWFLAKE_PASSWORD=tu-password
SNOWFLAKE_WAREHOUSE=tu-warehouse
SNOWFLAKE_DATABASE=tu-database
SNOWFLAKE_SCHEMA=PUBLIC

# Proveedores LLM - Configurar al menos uno
# Groq (opciÃ³n 1)
GROQ_API_KEY=tu-groq-api-key
MODEL_NAME=llama-3.3-70b-versatile

# Google Gemini (opciÃ³n 2) 
GOOGLE_API_KEY=tu-google-api-key
GEMINI_MODEL=gemini-1.5-flash

# SelecciÃ³n de proveedor (auto, groq, gemini)
LLM_PROVIDER=auto

# Opcional
DEBUG=False
```

### 3. Ejecutar la AplicaciÃ³n

```bash
# Activar entorno virtual
source venv/bin/activate

# Ejecutar aplicaciÃ³n
streamlit run streamlit_app.py
```

La aplicaciÃ³n estarÃ¡ disponible en `http://localhost:8501`

## ğŸ’» Ejemplos de Uso

### ğŸ” Consultas de Bases de Datos

```
ğŸ”¹ "?Â¿CuÃ¡les son los 10 pedidos con mayor valor?"
ğŸ”¹ "MuÃ©strame las ventas de este mes"
ğŸ”¹ "?Â¿CuÃ¡ntos clientes hay en total?"
ğŸ”¹ "Lista los productos mÃ¡s vendidos"
ğŸ”¹ "?Â¿QuÃ© base de datos estoy usando?"
ğŸ”¹ "Muestra las tablas disponibles"
ğŸ”¹ "?Â¿CuÃ¡l es el promedio de ingresos por regiÃ³n?"
```

### ğŸ¯ Consultas de Ayuda (Respuesta Educativa)

```
ğŸ”¹ "?Â¿En quÃ© me puedes ayudar?"
ğŸ”¹ "?Â¿QuÃ© puedes hacer?"
ğŸ”¹ "?Â¿CÃ³mo funciona esta aplicaciÃ³n?"
ğŸ”¹ "MuÃ©strame ejemplos de lo que puedes hacer"
```

### ğŸš« Consultas Fuera de Contexto (RedirecciÃ³n Amigable)

```
ğŸ”¹ "?Â¿CÃ³mo estÃ¡ el clima?"
ğŸ”¹ "CuÃ©ntame un chiste"
ğŸ”¹ "?Â¿QuÃ© pelÃ­culas recomiendas?"
â†’ Se redirige amigablemente a funcionalidades de BD
```

### Resultados AutomÃ¡ticos

La aplicaciÃ³n genera automÃ¡ticamente:
- âœ… **Consultas SQL** optimizadas y validadas
- ğŸ“Š **Tablas formateadas** con nombres de columnas amigables
- ğŸ’° **Formato monetario** para valores financieros
- ğŸ“ˆ **Contadores de registros** y estadÃ­sticas
- ğŸ” **Historial de conversaciÃ³n** persistente

## ğŸ—ï¸ Arquitectura

### Estructura del Proyecto

```
snowflake_nlp_agent_v2/
â”œâ”€â”€ ğŸ“„ streamlit_app.py         # AplicaciÃ³n principal
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ¤– agent/              # LÃ³gica NLP y LangChain
â”‚   â”‚   â””â”€â”€ nlp_agent.py
â”‚   â”œâ”€â”€ ğŸ—„ï¸  database/           # ConexiÃ³n Snowflake
â”‚   â”‚   â””â”€â”€ snowflake_conn.py
â”‚   â””â”€â”€ âš™ï¸  utils/              # ConfiguraciÃ³n y helpers
â”‚       â”œâ”€â”€ config.py
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ ğŸ“‹ requirements.txt        # Dependencias Python
â”œâ”€â”€ ğŸ”§ .env.example           # Template configuraciÃ³n
â””â”€â”€ ğŸ“š WARP.md                # DocumentaciÃ³n desarrollo
```

### TecnologÃ­as Clave

| TecnologÃ­a | PropÃ³sito | VersiÃ³n |
|------------|-----------|----------|
| **Streamlit** | Framework web | 1.28+ |
| **LangChain** | OrquestaciÃ³n LLM | 0.1+ |
| **Groq** | API LLM (Llama 3.3) âœ… | Latest |
| **Google Gemini** | API LLM (Gemini 1.5) âœ… | Latest |
| **Snowflake** | Data Warehouse | Connector 3.0+ |
| **Pandas** | ManipulaciÃ³n datos | 1.5+ |
| **SQLAlchemy** | ORM y conexiones | 2.0+ |

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno

| Variable | DescripciÃ³n | Requerido | Ejemplo |
|----------|-------------|-----------|---------|
| `SNOWFLAKE_ACCOUNT` | URL cuenta Snowflake | âœ… | `tu-org-account` |
| `SNOWFLAKE_USER` | Usuario Snowflake | âœ… | `usuario@empresa.com` |
| `SNOWFLAKE_PASSWORD` | ContraseÃ±a usuario | âœ… | `password123` |
| `SNOWFLAKE_WAREHOUSE` | Warehouse a usar | âœ… | `COMPUTE_WH` |
| `SNOWFLAKE_DATABASE` | Base de datos | âœ… | `PROD_DB` |
| `SNOWFLAKE_SCHEMA` | Schema por defecto | âŒ | `PUBLIC` |
| `GROQ_API_KEY` | API Key Groq (opciÃ³n 1) | ğŸ”„ | `gsk_...` |
| `GOOGLE_API_KEY` | API Key Google Gemini (opciÃ³n 2) | ğŸ”„ | `AIza...` |
| `MODEL_NAME` | Modelo Groq | âŒ | `llama-3.3-70b-versatile` |
| `GEMINI_MODEL` | Modelo Gemini | âŒ | `gemini-1.5-flash` |
| `LLM_PROVIDER` | SelecciÃ³n proveedor | âŒ | `auto`, `groq`, `gemini` |

**Nota:** ğŸ”„ = Al menos uno de los dos proveedores LLM debe estar configurado

### Comandos de Desarrollo

```bash
# Ejecutar con puerto especÃ­fico
streamlit run streamlit_app.py --server.port 8080

# Modo desarrollo con logs detallados
DEBUG=True streamlit run streamlit_app.py

# ProducciÃ³n (servidor pÃºblico)
streamlit run streamlit_app.py --server.port 8080 --server.address 0.0.0.0


# Verificar sintaxis
python -m py_compile streamlit_app.py

# Linting
flake8 src/ streamlit_app.py
```

## ğŸ”¬ Ejemplo de Flujo Detallado

Para entender cÃ³mo funciona la magia detrÃ¡s de escena, sigamos el viaje de una pregunta simple a travÃ©s del sistema.

**Pregunta del usuario:** `Â¿CuÃ¡les son los 10 clientes que mÃ¡s han gastado?`

---

#### **Paso 1: Interfaz de Usuario (Streamlit)**

1.  **Entrada del Usuario**: El usuario escribe la pregunta en el chat de la aplicaciÃ³n web (`streamlit_app.py`).
2.  **Procesamiento de Entrada**: La aplicaciÃ³n guarda y muestra inmediatamente el mensaje del usuario en la interfaz.
3.  **Llamada al Agente**: Se invoca al nÃºcleo del sistema: `agent.process_query(...)`.

---

#### **Paso 2: Capa del Agente NLP (LangChain + Groq)**

4.  **Inicio del Procesamiento**: El `SnowflakeNLPAgent` (`src/agent/nlp_agent.py`) recibe la consulta.
5.  **ConstrucciÃ³n del Prompt**: La `SQLDatabaseChain` de LangChain combina la pregunta del usuario con el esquema de las tablas de la base de datos y una plantilla de prompt en espaÃ±ol.
6.  **InvocaciÃ³n del LLM**: Se envÃ­a el prompt completo a la API de Groq, que utiliza el modelo `llama-3.3-70b-versatile`.
7.  **GeneraciÃ³n de SQL**: El LLM, guiado por el prompt, genera la consulta SQL correspondiente.
    ```sql
    SELECT c.c_name, SUM(o.o_totalprice) AS total_gastado
    FROM CUSTOMER c
    JOIN ORDERS o ON c.c_custkey = o.o_custkey
    GROUP BY c.c_name
    ORDER BY total_gastado DESC
    LIMIT 10
    ```
8.  **ExtracciÃ³n de SQL**: El agente extrae la consulta SQL generada de la respuesta de LangChain.

---

#### **Paso 3: Capa de Acceso a Datos (Snowflake)**

9.  **EjecuciÃ³n de la Consulta**: El agente ejecuta la consulta SQL a travÃ©s de la capa de conexiÃ³n a la base de datos (`src/database/snowflake_conn.py`).
10. **Procesamiento en Snowflake**: Snowflake recibe la consulta, la ejecuta en su motor de cÃ³mputo y devuelve los resultados. Por ejemplo:
    ```
    [('Customer#0001', Decimal('555285.16')), ('Customer#0002', Decimal('544089.09')), ...]
    ```
11. **RecepciÃ³n de Resultados**: La aplicaciÃ³n recibe estos resultados (una lista de tuplas).

---

#### **Paso 4: Formateo y VisualizaciÃ³n (Streamlit)**

12. **Formateo Inteligente**: Una funciÃ³n de utilidad (`format_sql_result_to_dataframe`) convierte la lista de tuplas en un DataFrame de Pandas, aplicando formato de moneda y nombres de columna amigables.
13. **VisualizaciÃ³n Final**:
    *   La aplicaciÃ³n muestra el DataFrame formateado en una tabla interactiva.
    *   Muestra un contador debajo de la tabla: `ğŸ“Š 10 registros encontrados`.
    *   La respuesta completa se guarda en el historial del chat.

---

#### **Paso 5: Trazabilidad (Logs en UI)**

14. **Panel de Logs**: Durante todo el proceso, se registran logs detallados que se muestran en el panel lateral, ofreciendo total transparencia sobre lo que hizo el sistema, desde la SQL que generÃ³ hasta los resultados que obtuvo.

## ğŸ”„ Actualizaciones Recientes (v2.2)

### âœ… Nuevas CaracterÃ­sticas Principales

- **ğŸ”„ Soporte Dual de LLM**: Groq/Llama + Google Gemini con auto-detecciÃ³n
- **ğŸ§  DetecciÃ³n HÃ­brida**: ClasificaciÃ³n inteligente de consultas (BD vs ayuda vs fuera de contexto)
- **ğŸ¯ Respuestas Educativas**: GuÃ­a completa con ejemplos para usuarios nuevos
- **ğŸš€ RedirecciÃ³n Amigable**: Respuestas amigables para consultas fuera de contexto
- **ğŸ“Š InformaciÃ³n DinÃ¡mica**: Sidebar muestra el modelo LLM activo en tiempo real

### âœ… Mejoras Anteriores (v2.1)

- **ğŸ¯ Formateo Inteligente**: Reconocimiento automÃ¡tico de tipos de consulta
- **ğŸ’¹ Formato Monetario**: VisualizaciÃ³n automÃ¡tica de valores financieros
- **ğŸ”§ Parsing Robusto**: Manejo avanzado de objetos Decimal de Snowflake
- **âš¡ Modelo Actualizado**: Llama 3.3 70B Versatile + Gemini 1.5 Flash
- **ğŸ–¥ï¸ UI Mejorada**: Tablas de ancho completo y contadores de registros

### ğŸ› Correcciones

- âœ… MÃ©todo obsoleto `__call__` reemplazado por `invoke`
- âœ… Manejo robusto de errores DataFrame constructor
- âœ… Parsing de strings con resultados SQL complejos
- âœ… ConfiguraciÃ³n dinÃ¡mica de proveedores LLM
- âœ… DetecciÃ³n automÃ¡tica de modelos disponibles

## ğŸ¤ ContribuciÃ³n

1. **Fork** el proyecto
2. Crear branch para feature (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add AmazingFeature'`)
4. Push al branch (`git push origin feature/AmazingFeature`)
5. Abrir **Pull Request**

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ†˜ Soporte

Â¿Problemas o preguntas?

- ğŸ“§ **Email**: soporte@empresa.com
- ğŸ› **Issues**: [GitHub Issues](https://github.com/tu-usuario/snowflake_nlp_agent_v2/issues)
- ğŸ“š **DocumentaciÃ³n**: Ver `WARP.md` para detalles tÃ©cnicos

## ğŸ™ Agradecimientos

- **Streamlit** por el framework web increÃ­ble
- **LangChain** por la orquestaciÃ³n de LLM
- **Groq** por los servicios de LLM rÃ¡pidos
- **Snowflake** por la plataforma de datos robusta

---

**Desarrollado con â¤ï¸ usando Python y tecnologÃ­as modernas de IA**
